---
title: "Data Processing"
author: "Team 2"
date: "2025-11-03"
output: pdf_document
---


```{r}

source("00_requirements.R")
data <- read.csv("00_ProstateCancer_Data.csv", header=T)

```

```{r}

cols1 <- c("Tani_Tarihi", "Tedavi_Tarihi", "PSA_Takip_3ay", "PSA_Takip_6ay", "PSA_Takip_12ay", "BCR_Tarihi", "Metastaz_Tarihi", "Son_Takip_Tarihi")

data <- data[, !(names(data) %in% cols1)]

```

```{r}

cols2 <- c("Klinik_Evre", "Biyopsi_Gleason", "Risk_Grubu", "Komorbidite_Skor", "Tedavi_Tipi", "ADT_Tipi", "Patolojik_Evre", "Cerrahi_Sinir", "Final_Gleason", "BCR_Durum", "Metastaz_Durum", "Son_Durum")

data[cols2] <- lapply(data[cols2], as.factor)

```

```{r}

names(data) <- c("Patient ID", "Age", "PSA_before", "CTstage", "GleasonScore_before", "RiskClass", "Albumin", "Lymphocyte", "CRP", "NLR", "CallyIndex", "ComorbidityScore", "Treatment", "RadiationDose", "HormoneType", "HormonDuration" ,"TumorSize", "MarginStatus", "GleasonScore_after", "PSA_after", "BCR", "Metastasis", "Survival")

```

```{r}

data$Delta_PSA <- data$PSA_before - data$PSA_after

```



## Data Analysis 0: Correlation between Variables

```{r}

vars <- c("Age", "PSA_before", "CTstage", "GleasonScore_before", "Albumin", "Lymphocyte", "CRP", "NLR", "CallyIndex", "ComorbidityScore")

pairs(data[, vars])

```



## Data Analysis 1: Logistic Regression (BCR)

```{r}

bcr_model <- glm(BCR ~ Age + PSA_before + CTstage + GleasonScore_before + Albumin + Lymphocyte + CRP + NLR + CallyIndex + ComorbidityScore + Treatment, data = data, family = binomial, na.action = na.omit)

summary(bcr_model)

plot(bcr_model, which = 1)

```

```{r}

bcr_model <- glm(BCR ~ PSA_before + Treatment, data = data, family = binomial, na.action = na.omit)

summary(bcr_model)

plot(bcr_model, which = 1)

```



## Data Analysis 2: Logistic Regression (Survival)

```{r}

survival_model <- glm(Survival ~ Age + PSA_before + CTstage + GleasonScore_before + Albumin + Lymphocyte + CRP + NLR + CallyIndex + ComorbidityScore + Treatment, data = data, family = binomial, na.action = na.omit)

summary(survival_model)

plot(survival_model, which= 2)

```

```{r}

survival_model <- glm(Survival ~ Treatment, data = data, family = binomial, na.action = na.omit)

summary(survival_model)

plot(survival_model, which = 2)

```



## Model Interpretation 1: Logistic Regression (BCR ~ Treatment)

```{r}

data$Treatment <- relevel(data$Treatment, ref = 3)

bcr_model_t3 <- glm(BCR ~ PSA_before + Treatment, data = data, family = binomial, na.action = na.omit)

summary(bcr_model_t3)

```



## Model Interpretation 2: Logistic Regression (BCR ~ Combination)

```{r}

data$Combination <- ifelse(data$Treatment == 4, "Yes", "No")
data$Combination <- as.factor(data$Combination)

bcr_model_2 <- glm(BCR ~ PSA_before + Combination, data = data,family = binomial, na.action = na.omit)

summary(bcr_model_2)

```



## Model Evaluation:

### Model Fitting and Predicting

```{r, echo=FALSE}

vars_for_model <- c("BCR", "PSA_before", "Treatment")
model_data <- data[complete.cases(data[, vars_for_model]), vars_for_model]

set.seed(123)
split_tag <- sample.split(model_data$BCR, SplitRatio = 0.70)
train_set <- subset(model_data, split_tag == TRUE)
test_set <- subset(model_data, split_tag == FALSE)

set.seed(123)
balanced_train_data <- ovun.sample(
    BCR ~ ., 
    data = train_set, 
    method = "over", 
    N = 2 * sum(train_set$BCR == "False") 
)$data

bcr_model_train <- glm(BCR ~ PSA_before + Treatment,data = balanced_train_data, family = binomial)

test_probabilities <- predict(bcr_model_train, newdata = test_set, type = "response")

```


### Evaluating: AUC (Area Under the Curve)

```{r, echo=FALSE}

train_probabilities <- predict(bcr_model_train, newdata = train_set, type = "response")

roc_obj_train <- roc(train_set$BCR, train_probabilities)
auc_score_train <- auc(roc_obj_train)

roc_obj <- roc(test_set$BCR, test_probabilities)
auc_score <- auc(roc_obj)

par(mfrow = c(1, 2))

plot(roc_obj_train, 
     main = "ROC Curve for Training Set",
     xlab = "False Positive Rate (1 - Specificity)", 
     ylab = "True Positive Rate (Sensitivity)",
     lwd = 3)

plot(roc_obj, 
     main = "ROC Curve for BCR Test Model",
     xlab = "False Positive Rate (1 - Specificity)", 
     ylab = "True Positive Rate (Sensitivity)",
     lwd = 3)

auc_results <- data.frame(
  Dataset = c("Training Set", "Test Set"),
  AUC = c(
    sprintf("%.4f", auc_score_train), 
    sprintf("%.4f", auc_score)
  )
)

auc_results %>%
  knitr::kable(
    caption = "Model Performance: Area Under the Curve (AUC)",
    format = "latex", 
    align = c('l', 'r') 
  )

```


### Confusion Matrix (Threshold 0.5)

```{r}

test_predictions <- ifelse(test_probabilities > 0.5, "True", "False")
conf_matrix <- table(Predicted = test_predictions, Actual = test_set$BCR)
conf_matrix <- conf_matrix[, c("False", "True")]

accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
sensitivity <- conf_matrix["True", "True"] / sum(conf_matrix[, "True"])
specificity <- conf_matrix["False", "False"] / sum(conf_matrix[, "False"])

conf_df <- as.data.frame.matrix(conf_matrix)
conf_df <- tibble::rownames_to_column(conf_df, var = "Predicted") %>%
  rename(`Actual (BCR=False)` = False, `Actual (BCR=True)` = True)

conf_df %>%
  kable(
    caption = "Confusion Matrix (Threshold 0.5)",
    col.names = c("Predicted", "False", "True"),
    booktabs = TRUE,
    align = 'c'
  ) %>%
  add_header_above(c(" " = 1, "Actual Status" = 2)) %>%
  kable_styling(
    latex_options = c("hold_position"), 
    full_width = FALSE
  )

metrics_df <- data.frame(
  Metric = c("Accuracy", "Sensitivity", "Specificity"),
  Value = c(accuracy, sensitivity, specificity)
) %>%
  mutate(Value = sprintf("%.4f", Value))

metrics_df %>%
  kable(
    caption = "Performance Metrics (Threshold 0.5)",
    booktabs = TRUE,
    align = c('l', 'c')
  ) %>%
  kable_styling(
    latex_options = c("hold_position"), 
    full_width = FALSE
  )

```